{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92535b4c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Introduction to Probability and its Applications\n",
    "\n",
    "## LSST DA Data Science Fellowship Program Session 23, Pittsburgh, PA\n",
    "### Bryan Scott, CIERA/Northwestern University\n",
    "Based on \n",
    "- Lectures by David Hunter and Hyungsuk Tak given at the 14th Penn State School in Astrostatistics\n",
    "- Probability Theory: The Logic of Science by ET Jaynes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe0f408",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Overview and Pedagogical Strategy\n",
    "\n",
    "This section will cover:\n",
    "\n",
    "- Terminology that statisticians use to discuss probability\n",
    "- Core concepts of probability theory from an intuitive (not rigorous/first principles) perspective\n",
    "- Axioms of probability theory\n",
    "- Origins of Bayes relationship as a result in probability theory\n",
    "\n",
    "By the end, you should be able to:\n",
    "\n",
    "- Derive the Bayes relationship from \"first principles\"\n",
    "- Make use of the relationships in probability theory to solve problems involving randomness\n",
    "- Assign probabilities to events"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bcb0352",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "My pedagogical strategy is:\n",
    "\n",
    "- Start from simple claims and build more complex ideas out of them in a step by step fashion. \n",
    "- Introduce and define jargon multiple times. \n",
    "\n",
    "This will form the basis for:\n",
    "\n",
    "- Tomorrow's discussion of priors and likelihood functions\n",
    "- The application of the Bayes relationship to the practice of Bayesian inference (throughout the week)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b4032e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Part 1: Let's define some jargon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b214c0d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### We define the following terms:\n",
    "\n",
    "- The **Outcome space**, denoted $\\Omega$  is the set of possible **outcomes** of some process. We can write this as,\n",
    "\n",
    "$\\Omega = \\{o_1, o_2, ... o_n\\}$\n",
    "\n",
    "So, for example, the outcome space for a coin is {H, T}, and for a 6-sided die, {1, 2, 3, 4, 5, 6}.\n",
    "\n",
    "- An **Event** is a subset of the Sample Space. $E \\in \\Omega$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e23200",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Technical note: A **discrete sample space** is either **finite** or **countably infinite**. This definition helps with the formal mapping between outcomes in the sample space and the notion of probability. In astronomical applications, we largely ignore the technical issues that come with whether our outcome spaces are discrete or continuous (\"not countably infinite\"). In this case we need a more sophisticated notion of a **probability space**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dafd25c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## An Important and Confusing Term: The \"Random Variable\"\n",
    "\n",
    "A **random variable** is a **map** from the **outcome space** to the **real numbers**. There are a few notations for a random variable, for example:\n",
    "\n",
    "- Formally, $X: \\Omega \\rightarrow R$ defines the map from the outcome space to (a subset?) of the real numbers \n",
    "\n",
    "- If we want to consider a specific sort of event, we write $\\{\\omega \\in \\Omega: x \\in X\\}$\n",
    "\n",
    "- The short hand for the above is $\\{X = x\\}$\n",
    "\n",
    "Careful, the random variable X is the **map**, not the specific **outcome or event**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d69b1ab",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Probabilities and Random Variables\n",
    "\n",
    "The **probability mass function** associated with a **random variable** is a map between the elements of the outcome space, the **events**, and real numbers. It is written in shorthand as P(X = x) and more verbosely as, \n",
    "\n",
    "$P(\\{\\omega \\in \\Omega: x \\in X\\} = P(\\{\\omega \\in \\{H, T\\}: X(\\omega)) = T\\})$ = 1/2\n",
    "\n",
    "for the example of example of flipping a coin and getting tails is."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fed93d9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## How do we assign probabilities?\n",
    "\n",
    "Take a moment and discuss this with those around you. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d78cff",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Principle of \"Insufficient Reason\" or \"Indifference\"\n",
    "\n",
    "First formulated by Laplace and Bernoulli, Keynes (en route to criticizing it) defined this principle as:\n",
    "\n",
    "\"If there is no known reason for predicating of our subject one rather than another of several alternatives, then relatively to such knowledge the assertions of each of these alternatives have an equal probability.\"\n",
    "\n",
    "So if I flip a coin, I assign uniform probability to all outcomes given by N/M (for N identical outcomes out of M possibilities) = 1/2 for {H, T}, 1/6 for flipping a coin {1, 2, 3, 4, 5, 6}. \n",
    "\n",
    "We will discuss this principle in the section on Priors and Likelihoods, I will also invite you to consider a physical justification for the principle as a challenge problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac54fb32",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Functions of random variables\n",
    "\n",
    "Fact: Any function of a random variable is itself a random variable. \n",
    "\n",
    "Problem: We often measure some variable x, but the result we are interested n is a function y(x). What is the distribution P(y)? If y = $\\Phi(x)$ and hence $x = \\Phi^{-1}(y)$,\n",
    "\n",
    "$$ p(y) = p[\\Phi^{-1}(y)] \\left|\\frac{d \\Phi^{-1}(y)}{d y} \\right|$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e10f233",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Some important remarks: \n",
    "\n",
    "* Cumulative statistics are invariant under monotonic transformations (they map to the same data point) - this provides the basis for a number of statistical tests that compare distributions. \n",
    "\n",
    "* The standard uncertainty propogation formulas are derived by a taylor expansion of the uncertainty to first order, \n",
    "\n",
    "$$ \\sigma_y = \\left| \\frac{d \\Phi(x)}{dx} \\right| \\sigma_x $$\n",
    "\n",
    "Careful: these formulas only work if it is sufficient to keep only the first order terms in the transformation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb5d73e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Part 2: Kolmogorov Axioms of Probability Theory\n",
    "\n",
    "There are three basic axioms that restrict the form that P can take:\n",
    "\n",
    "$$P(\\omega) \\ge 0 \\space \\forall \\space \\omega \\in \\Omega$$ (probabilities are never negative)\n",
    "\n",
    "$$\\Sigma_i P(\\omega_i) = 1$$ \n",
    "\n",
    "if the $\\omega_i$ span the entire outcome space. (probabilities must sum to 1)\n",
    "\n",
    "$$P(\\cup_i^\\infty \\omega_i) = \\Sigma P(\\omega_i)$$ \n",
    "\n",
    "for disjoint $\\omega_i$ (countable additivity or \"the sum rule\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53afc831",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Sum Rule Venn Diagram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1795470",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Part 3: A Quick Proof of the Bayes' rule: Conditional Probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc516893",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Suppose you have some event, which we will call $A$. We define the probability of event $A$ occurring as:\n",
    "\n",
    "$$P(A).$$\n",
    "\n",
    "Now suppose we want to know the probability that both event $A$ and event $B$ occur: $P(A \\cap B)$. At first glance, it seems like this ought to be the product of the probability of $A$ and the probability of $B$:\n",
    "\n",
    "$$P(A \\cap B) = P(A)\\,P(B).$$\n",
    "\n",
    "This is the product rule if $A$ and $B$ are *independent*. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5220c18a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "To see why this is true, imagine a single coin. If event $A$ is a flip landing in heads, and event $B$ is a flip landing in tails, then $P(A)\\,P(B) = 1/4$. \n",
    "\n",
    "What if P(A) depends on the P(B)?\n",
    "\n",
    "In that case, the probability of $A$ *and* $B$ therefore requires a statement about conditional probability:\n",
    "\n",
    "$$P(A \\cap B) = P(A\\mid{B})\\,P(B),$$\n",
    "\n",
    "which should be read as \"the probability of $A$ and $B$ is equal to the probability of $A$ given $B$ multiplied by the probability of $B$.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5744a8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Product Rule Venn Diagram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e2d5af",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The probability of $A$ and $B$ must be equal to the probability of $B$ and $A$, which leads to:\n",
    "\n",
    "$$P(A\\mid{B})\\,P(B) = P(B\\mid{A})\\,P(A),$$\n",
    "\n",
    "which we can rearrange as:\n",
    "\n",
    "$$P(A\\mid{B}) = \\frac{P(B\\mid{A})\\,P(A)}{P(B)}.$$ (This is the Bayes' Rule)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968cca3c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Conditionalization and the Law of Total Probability\n",
    "\n",
    "First we define the concept of a **partition** of a set. A partition is a set of disjoint sets whose unions is the outcome space, $\\Omega$.\n",
    "\n",
    "Then, the law of total probability says that the probability of an event, A, can be found by summing over all of the ways A and events in the partition of $\\Omega$ can occur, mathematically,\n",
    "\n",
    "$$ P(A) = \\Sigma_i^N P(A \\cap B_i) $$\n",
    "\n",
    "The definition of $P(A \\cap B)$ allows us to write,\n",
    "\n",
    "$$ P(A) = \\Sigma_i^N P(A|B_i)P(B_i) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab78598",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Example of the Law of Total Probability:  \n",
    "\n",
    "$$ P(\\text{H on four flips}) = P(H|\\text{not trick}) \\times P(\\text{not trick}) + P(H |\\text{trick}) \\times P(\\text{trick}) $$\n",
    "\n",
    "$$ P(\\text{H on four flips}) = \\left(\\frac{1}{2}\\right)^4 \\times \\frac{5}{6} + 1 \\times \\frac{1}{6} = \\frac{7}{32}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9df20c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Aside: Alternative Axioms:\n",
    "\n",
    "What if instead of requiring that all probabilities: \n",
    "\n",
    "$$P(\\omega) \\ge 0 \\space \\forall \\space \\omega \\in \\Omega$$\n",
    "\n",
    "We instead have the requirement that:  \n",
    "\n",
    "$$P(\\omega) \\in \\mathscr{R}  \\space \\forall \\space \\omega \\in \\Omega$$\n",
    "\n",
    "and we retain one of the two remaining Kolmogorov axioms:\n",
    "\n",
    "$$P(\\cup_i^\\infty \\omega_i) = \\Sigma P(\\omega_i)$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d65a90",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Take two minutes to discuss with your neighbor why you might prefer the Kolmogorov axioms to my alternative proposal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9dd03c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can interpret a negative probability the same way we interpret negative numbers - we never question that we can use the number \"-5\", for example of apples, as a calculational shorthand. We instead merely require that the final result of any calculation which concerns real physical apples results in a positive number of (or perhaps 0) apples. \n",
    "\n",
    "Negative probabilities would work similarly. We would require:\n",
    "\n",
    "$$ P(A) = \\Sigma_i^N P(A_i|B)P(B)  \\ge 0 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2beb9534",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src= \"negative_prob_table.png\" alt=\"drawing\" width=\"700\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0c8a54",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "If we know that condition A happens 70% of the time and condition B 30% of the time, then\n",
    "\n",
    "P(1) = 0.7* 0.3 + 0.3*(-0.4) = 0.09\n",
    "\n",
    "P(2) = 0.7 * 0.6 + 1.2*(0.3) = 0.78 \n",
    "\n",
    "P(3) = 0.7 * 0.1 + 0.3 * 0.2 = 0.13\n",
    "\n",
    "and we therefore have a well defined final result. The probability P(1) + P(2) + P(3) = 1 as our second axiom required for these to be probabilities on the alternative axioms. \n",
    "\n",
    "(Note that A and B here do not have the same meaning as in the sum on the previous slide)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db02a1bd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Disturbed? So am I. This example comes from a famous paper by [Richard Feynman](https://cds.cern.ch/record/154856/files/pre-27827.pdf/). It is worth a read."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a308c7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Part 4: Relationship Between Probability and Inference\n",
    "\n",
    "As scientists, do we care about this probability? I would argue we are much more interested in the idea of **explanation**, which is what the Bayes' rule now allows us to attempt. We will **condition** our explanation on the **data** as follows:\n",
    "\n",
    "$$ P(\\text{trick} | \\text{H on four flips}) = \\frac{P(\\text{H on four flips}| \\text{trick})P(\\text{trick})}{P(\\text{H on four flips})} = \\frac{16}{21}$$\n",
    "\n",
    "which captures are intuition that, if we think the coin is rigged and the flips don't go our way, that we're probably being cheated! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab35195",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "This example illustrates the relationship between probability and inference. \n",
    "\n",
    "$$ \\text{Roughly: Probability explains how likely various outcomes (observations) are, given the model parameter }  \\theta, \\text{while inference quantifies the uncertainty about } \\theta\\text{, given observed data x.} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2a540b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In classical statistics, we think of the problems we encounter in the following way: \n",
    "\n",
    "There exists a **population** from which we **sample** (select subsets of). We describe the sample with sets of descriptive **statistics**, for example, the sample **mean**, the sample **variance**, the sample **skeweness**, the sample **kurtosis**, etc.\n",
    "\n",
    "We then use the **sample statistics** to do inference, that is, to estimate, or infer, the parameters of the unobserved **population probability distribution**. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5d2346",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Part 5: What is Probability?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87110992",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "If you review this lecture, you'll notice something disturbing. I haven't defined precisely what probability is. This is because there is, in fact, no consensus interpretation beyond the notion of maps and the Kolgomorov axioms. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca529a29",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The basic debate comes down to the status of the parameters $\\theta$. There are two perspectives: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58b7bac",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* The $\\theta$ are fixed parameters to be estimated from (possibly) many repeated samples of the population. The sampling or the realization of the random process is the source of randomness. Our **estimates** have an associated probability distribution. Probability is thought of in terms of the long run frequency of events. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ddfe8f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* The data are fixed - produced by some underlying physical process. $\\theta$ is some random variable with associated probability distributions $p(\\theta)$ and $p(\\theta | D)$. Probability is a measure of our uncertainty about $\\theta$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2628709c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The former interpretation is often called the classical or frequentist interpretation, owing to its focus on the notion of repeated sampling. The latter is called the Bayesian interpretation, after the Rev. Thomas Bayes, who first argued for it in a posthumous essay. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57e13d1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Although you are (almost always) free to work within either interpretation, the dominant view in contemporary astronomy is a Bayesian one. "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
