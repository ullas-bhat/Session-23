{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2fe8683",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Priors, Likelihoods, Posteriors, and All That\n",
    "\n",
    "\n",
    "## LSST DA Data Science Fellowship Program Session 23, Pittsburgh, PA \n",
    "### Bryan Scott, CIERA/Northwestern University\n",
    "Based on \n",
    "\n",
    "- Probability Theory: The Logic of Science by ET Jaynes\n",
    "- Statistics, Data Mining, and Machine Learning in Astronomy, by Željko Ivezić, Andrew Connolly, Jacob Vanderplas, and Alex Gray\n",
    "- Data Analysis: A Bayesian Tutorial by DS Sivia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec840ae",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Overview and Pedagogical Strategy\n",
    "\n",
    "This section will cover:\n",
    "\n",
    "- The role of prior distributions in Bayesian inference\n",
    "- Practical principles for assigning or picking prior distributions\n",
    "- The conditions under which the choice of prior can make a difference for your posterior\n",
    "- The reasons why certain priors, likelihoods, and posteriors are common  \n",
    "\n",
    "My pedagogical strategy is:\n",
    "\n",
    "- Start with something you (probably) know well, study it closely, then introduce new takes on the same idea.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13e21b8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Part 0: Reminders about Bayesian Inference\n",
    "\n",
    "As we've now seen, Bayes theorem is written\n",
    "\n",
    "$$ P(H|D, I) = \\frac{P(D|H,I)P(H|I)}{P(D|I)}$$\n",
    "\n",
    "* P(H|D, I) is called the $\\textbf{posterior}$\n",
    "* P(D|H, I) is called the $\\textbf{likelihood}$\n",
    "* P(H| I) is called the $\\textbf{prior}$\n",
    "* P(D| I) is called the $\\textbf{evidence}$ or sometimes the $\\textbf{fully marginalized likelihood}$ (thank you to Adrian for pointing this out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4c7aa4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "As scientists, our goal is to construct models of the world based on what we observe. So our goal is to calculate posterior probabilities that are theories are true. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f57a47",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Calculating the evidence is a difficult computational task and involved in the problem of model comparison. However, if we have one model for the data and want to estimate its parameters, we can ignore the bayesian evidence and simply normalize our posterior probability distributions after we are done. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5351193a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "That leaves us with the (possibly) significant problem of determining the functional form of the likelihood and assigning priors to our model parameters. \n",
    "\n",
    "The most common distribution in both Bayesian (and classical inference) is the Gaussian. So let's take a minute and try to understand why it arises so often.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c702e436",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Part 1: The Central or Gaussian Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fb1fac",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Part 1a:  The Herschel–Maxwell derivation\n",
    "\n",
    "Many of the earliest clear derivations of the Gaussian distribution come from astronomy. In fact, much of statistical inference was concerned with fitting the orbits of planets and positions of stars. William Herschel considered the problem, speicifically, of estimating the position of a star given noise in both the x and y directions (we'll assume some sort of \"flat sky\" approximation). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fbfd98d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Herschel argued that if the uncertainties in the stellar positions are independent of where on the sky you're measuring, two things must be true: \n",
    "\n",
    "* P1) The error in the x- and the error in the y- direction must be independent. \n",
    "* P2) The probability of the star having some x,y position is independent of the angle between x and y."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccfa170b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\"P1: The error in the x- and the error in the y- direction must be independent\" implies that the probability distribution for the x-y position factors,\n",
    "\n",
    "$$ \\rho(x, y) dx dy = f(x) dx \\times f(y) dy $$\n",
    "\n",
    "if we write this in polar coordinates $(r, \\theta)$, \n",
    "\n",
    "$$ \\rho(x, y) dx dy = g(r, \\theta) r dr d\\theta $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5027a73",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "P2 implies that this probability distribution is solely a function of $r = \\sqrt{x^2 + y^2}$\n",
    "\n",
    "$$ f(x) f(y) = f\\left(\\sqrt{x^2 + y^2}\\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa2cc59",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's consider the x- and y- parts separately by setting y = 0 and take the log of both sides. Then we have a functional equation, \n",
    "\n",
    "$$ \\log{\\left[\\frac{f(x)}{f(y=0)}\\right]} + \\log{\\left[\\frac{f(y)}{f(y=0)}\\right]} = \\log{\\left[\\frac{f\\left(\\sqrt{x^2 + y^2}\\right)}{f(y=0)}\\right]} $$\n",
    "\n",
    "for the left and right sides to be equal, f(x) = $\\alpha x^2$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863c4c0f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Since an identical argument works in the y-direction, we arrive at \n",
    "\n",
    "$$ \\rho(x,y) = \\frac{\\alpha}{\\pi} \\exp{\\left(-\\alpha (x^2 + y^2)\\right)} $$\n",
    "\n",
    "Maxwell used a similar argument to show that the 3D velocity distribution of a classical gas is Gaussian."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e5ac84",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Part 1b: The Landon derivation \n",
    "\n",
    "A much later example of the Gaussian distribution concerns the distribution of electrical noise voltages. The key idea is that a sort of invariance in this distribution uniquely fixes the functional form of the noise voltage probability distribution. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e47033b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Suppose that the distribution of voltages in a circuit at a set of times is not given by a single fixed distribution, but a hierarchy of distributions,\n",
    "\n",
    "$$ p(\\nu | \\sigma^2) $$ \n",
    "\n",
    "where $\\sigma^2$ is the square of the noise voltage. If increasing the voltage in the circuit also increases the noise level, Landon posited that the distribution would have the same functional form just at a new location in the distribution hierarchy. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64c4a63",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Suppose that the difference between the new and old voltage is given by $\\nu' = \\nu + \\epsilon$ where $\\epsilon \\sim q(\\epsilon) d\\epsilon$. The product and sum rules of probability require that the distribution of the voltage $\\nu'$ be given by\n",
    "\n",
    "$$ f(\\nu') = \\int d\\epsilon p(\\nu' - \\epsilon | \\sigma) q(\\epsilon) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23e5160",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The key step is to relate the new distribution $f(\\nu')$ to the old distribution $p(\\nu | \\sigma)$. We can do this with a taylor expansion for $f(\\nu')$, \n",
    "\n",
    "$$ f(\\nu') = p(\\nu | \\sigma) - \\frac{\\partial p(\\nu | \\sigma)}{ \\partial \\nu} \\int d\\epsilon \\epsilon q(\\epsilon) + \\frac{1}{2} \\frac{\\partial^2 p(\\nu | \\sigma)}{\\partial \\nu^2} \\int d\\epsilon \\epsilon^2 q(\\epsilon) + ... $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391839c1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "the integrals are just the expectation values for $\\epsilon$ and $\\epsilon^2$. For a zero mean process, $\\left< \\epsilon \\right> = 0$ and if $\\left< \\nu^2 \\right> = \\sigma^2 + \\left< \\epsilon^2 \\right> $, then,\n",
    "\n",
    "$$ f(\\nu') = p(\\nu | \\sigma) + <\\epsilon^2> \\frac{\\partial p(\\nu | \\sigma)}{\\partial \\sigma^2} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa227372",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "which implies that for the functional form of the probability distribution to be independent of the voltage level, \n",
    "\n",
    "$$ \\frac{ \\partial p(\\nu | \\sigma)}{\\partial \\sigma^2} = \\frac{1}{2} \\frac{\\partial^2 p(\\nu | \\sigma)}{\\partial \\nu^2} $$\n",
    "\n",
    "which is the diffusion equation. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1040dce2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The solution is, \n",
    "\n",
    "$$p(\\nu | \\sigma) = \\frac{1}{\\sqrt{2 \\pi \\sigma^2}} \\exp \\left(- \\frac{\\nu^2}{2\\sigma^2}\\right) $$\n",
    "\n",
    "which is a gaussian distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26abf5f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Okay, so what matters here? The key point is not the math to get to the gaussian distribution, but that the general approach. Adding small increments through successive processes is very common in nature (think collisions in a classical gas) and can produce gaussian distributions. The intuition that such successive convolutions of probability distributions in a hierarchy can generate \"special\" distributions is the takeaway."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6054cb63",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Part 1c: The Gauss derivation \n",
    "\n",
    "Another important derivation was given by Gauss. The key step in the Gauss derivation is to equate the maximum likelihood estimate with the arithmetic mean of the observations,\n",
    "\n",
    "(maximum likelihood) = (arithmetic mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1eddac1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Criticism of this approach centered on the (at the time) widely believe idea that errors accumulated rather than cancelled. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17c8866",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "This in fact, was contradicted by anyone who had worked with data, who knew already that averaging many measurements led to cancellations. As always, theorists take a long time to catch up with what experimentalists already know. The proof is outlined and left as an exercie in the problem session."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4670c89",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Part 1d: The Central Limit Theorem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd77524",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "If you consult the wikipedia page on the central limit theorem, you will find the following definition,\n",
    "\n",
    "If $X_1, X_2,...,X_n$ are random samples drawn from a population with mean $\\mu$ and variance $\\sigma^2$, and if $\\bar{X}_n$ is the sample mean of the first n samples, then the limiting form of the distribution $Z = \\frac{(\\bar{X}_n - \\mu)}{\\sigma_{\\bar{X}_n}}$ with standard error of the mean, $\\sigma_{\\bar{X}_n} = \\sigma/n$ is normally distributed. \n",
    "\n",
    "Motivating (but not proving) this (from a slightly more Bayesian perspective) is left as a challenge problem in the exercises. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1a0d2e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Part 2: Uniform \"uniformative\" Priors\n",
    "\n",
    "### Flat priors\n",
    "\n",
    "The $\\textbf{principle of consistency}$ says that the prior distribution should not change because of a transformation of the underlying coordinates. That is, if I move everything uniformly, my prior probabilities should remain the same in the new coordinates. This yields a \\textbf{flat prior}, \n",
    "\n",
    "$$ p(\\theta | I) = \\theta. $$ \n",
    "\n",
    "While a flat prior is intuitive, it has a problem - transformations of $\\sigma$ aren't shape preserving. Compare this with yesterday's discussion of the $\\textbf{principle of indifference}$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e48258",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Scale Invariant Priors\n",
    "\n",
    "The same prior information can yield different prior distributions based on different principles. For example, if we replace the $\\textbf{principle of consistency}$ with a $\\textbf{symmetry principle}$, which states that a scale parameter should be unit independent, the prior distribution is,\n",
    "\n",
    "$$ p(\\theta | I) = \\theta^{-1}. $$\n",
    "\n",
    "which is equivalent to a flat prior in $\\log{\\theta}$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43369b6e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Part 3: Yet more line fitting\n",
    "\n",
    "As we saw yesterday, we can transform probability distributions by  \n",
    "\n",
    "$$ p(y) = p[\\Phi^{-1}(y)] \\left|\\frac{d \\Phi^{-1}(y)}{d y} \\right|$$\n",
    "\n",
    "let's consider two ways of fitting a line. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6ca9f3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In the first case, we fit for the parameters ($\\alpha$, $\\beta$),\n",
    "\n",
    "$$ y = \\alpha + \\beta x $$\n",
    "\n",
    "In the second case, we fit for the parameters ($\\alpha'$, $\\beta'$) defined by\n",
    "\n",
    "$$ x = \\alpha' + \\beta' y $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9af47f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Our prior distributions are defined over the parameters ($\\alpha$, $\\beta$) and ($\\alpha'$, $\\beta'$). We have\n",
    "\n",
    "$$ P(\\alpha, \\beta) d\\alpha d\\beta $$\n",
    "\n",
    "and \n",
    "\n",
    "$$ Q(\\alpha', \\beta') d\\alpha' d\\beta' $$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b197f7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can use the definitions of the two functions we are fitting to write each distribution in terms of the other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d36794",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now here's the clever part. The change of variables should not impact the proir probabilities that we assign. We can express this in terms of a transformation between the two sets of parameters. We have,\n",
    "\n",
    "$$ \\beta^3 P(\\alpha, \\beta) = P(-\\beta^{-1} \\alpha, \\beta^{-1}) $$\n",
    "\n",
    "which is a functional equation with solution\n",
    "\n",
    "$$ P(\\alpha, \\beta) \\propto (1+\\beta^2)^{-3/2} $$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789d9ac2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "What this means is that a uniform prior on $\\beta$ is uniform prior on $\\sin{\\theta}$ (and hence, a nonuniform prior on the angle a line makes with the x-axis).\n",
    "\n",
    "Why? The short answer is that this results from keeping a uniform prior on the intercept $\\alpha$. If we perform a coordiante transformation in $\\alpha$ to include information about the angle, we can construct uniform priors on both transformed parameters (at the cost of no longer uniform priors on the untransformed parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ed1569",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Part 4: When does the choice of Prior matter? \n",
    "\n",
    "### Part 4a) Small data limit\n",
    "\n",
    "$$\n",
    "\\textbf{On the board} \n",
    "$$\n",
    "\n",
    "### Part 4b) Concavity/shape\n",
    "\n",
    "$$\n",
    "\\textbf{On the board} \n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8f118002",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Part 5: Examples from real research problems\n",
    "\n",
    "<center>\n",
    "<img src=\"apj523533f6_lr.jpg\" alt=\"drawing\" width=\"400\"/>\n",
    "</center>\n",
    "\n",
    "\"The results of this uniform grid test are shown in Figure 6. In regions of this uniform mock \"Galaxy,\" where spiral arm information is lacking, the grid is reasonably well preserved. However, where the spiral arm information exists and is used in the combined distance PDF, the results are biased to arms. This highlights the effects of the assumption made in the Bayesian distance estimation method that sources whose (l, b, v)src values are similar to the (l, b, v)arm values of a known spiral arm segment probably are in that arm. Therefore, one should not use this method for sources that are not, or only weakly, associated with spiral structure, such as populations of old stars or diffuse gas.\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b6c111",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center>\n",
    "<img src=\"priors_in_cosmology.png\" alt=\"drawing\" width=\"800\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423537e6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "A famous example has to do with parallax measurments! You'll work through this in the problem session!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924ee972",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Part 6: Advanced Topics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5573d54b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Part 6a) Jefreys' prior \n",
    "\n",
    "We will shortly introduce maximum entropy. Closely related is the idea of information, a measure of how surprised we are by a result. Since surprisal and probability are related, it seems sensible to study a quantity involving changes in probability distributions:\n",
    "\n",
    "$$\n",
    "I(\\theta) = - \\textbf{E}^{X|\\theta}\\frac{\\partial^2 \\log{f(x|\\theta)}}{\\partial \\theta^2}\n",
    "$$\n",
    "\n",
    "This is a measure of the curvature of the likelihood. A common use of this expression is to design experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec5564f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "It turns out that the prior distribution defined as the \n",
    "\n",
    "$$\n",
    "\\pi(\\theta) = \\det \\left(\\sqrt{I(\\theta)}\\right)\n",
    "$$\n",
    "\n",
    "is independent of parameterization. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37f97cc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "It therefore has a special name, called the Jefreys prior, and is a common choice for prior since it expresses the idea of a flat prior on $\\textbf{parameter choice}$ rather than parameter value. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663c131e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Part 6b) Conjugate Priors\n",
    "\n",
    "When the posterior has the same functional form as the prior, the prior is called $\\textbf{conjugate}$. Some common conjugate priors are, \n",
    "\n",
    "* The gaussian distribution is conjugate to itself. If the likelihood and prior are gaussian, so is the posterior. this property is part of what makes the gaussian distribution so common. A detail here is that the posterior estimates will be biased (not converge to the \"true\" parameters) if the mean and variance are estimated from the data.\n",
    "\n",
    "* For discrete problems, the beta distribution is conjugate to the binomail likelihood, and the gamma distribution is conjugate to the Poisson distribution. \n",
    "\n",
    "This is in some sense 'trivia'. It is rarely necessary for astronomers to know libraries of distributions and their conjugates. Instead, you should test the sensitivity of your inference to changes in your priors. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88883a14",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "A common use of conjugate priors is to study how parameter estimates converge with the addition of more data. For real problems, we tend to prefer \"uniformative priors\" or those derived from the maximum entropy principle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c09236f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Part 6c) Principle of Maximum Entropy\n",
    "\n",
    "Suppose we are not completely ignorant about the values of some model parameters, but, for example, know some ratios of the parameters but not the parameters themselves. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f302808c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Then, it seems that assigning uninformative priors would be too conservative. We know $\\textbf{something}$ about the probability distribution and we should encode that in our approach to Bayesian inference. Our problem is to assign the most uniformative prior distribution while respecting the available information. This is an optimization or variational problem. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36f9ccb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In the Bayesian interpretation of probability, we think of probabilities as quantifying our uncertainty about the world. Claude Shannon studied a related problem in the 1940s. Similar to the probability axioms we looked at yesterday, there are four assumptions that allow us to quantify the \"amount of uncertainty\". They are,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b01f93f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* P1) Such a numerical measure (a map from $uncertainty \\rightarrow \\mathscr{R}$), called $H_n (p_1, ..., p_n)$ exists.\n",
    "* P2) $H_n$ is a continuous map\n",
    "* P3) This measure should capture the common sense notion that few options make us more certain than when there are many options.\n",
    "* P4) $H_n$ is consistent, that is, every way of calculating $H_n$ yields the same answer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e682d20",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "P3 and P4 turn out to uniquely fix the form of $h(n) = H_n (1/n, ..., 1/n)$ for $n$ equally likely possibilities. \n",
    "\n",
    "$$ h(n) = k log(n) $$\n",
    "\n",
    "Which is called the Shannon entropy. It is possible (but non-trivial) to extend this to continuous spaces, non-uniform possibility spaces, etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c9ccf4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Some facts. \n",
    "\n",
    "* If we have a fixed mean and variance for our prior distribution, the principle of maximum entropy yields the Gaussian distribution as the best prior that respects our existing knowledge fo the problem.\n",
    "* If we have an upper or lower bound on a parameter (for example, some things can't be negative), the maximum entropy principle yields the exponential distribution.\n",
    "\n",
    "The maximum entropy principle can be used to derive other prior probability distributions in situations where we are not entirely ignorant about a problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4340d90b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Problem Session\n",
    "\n",
    "In the problem session, you will explore \n",
    "\n",
    "* Sampling for high dimensional problems \n",
    "* An example where choices about prior distributions matter for inference\n",
    "* Non-gaussian likelihood functions\n",
    "* The origin of Gaussianity "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
